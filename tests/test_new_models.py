#!/usr/bin/env python3
"""
Test the model-specific configuration for the new models.
"""

import logging
import sys
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.INFO)

from job_board_aggregator.api.cerebras.cerebras_validator import CerebrasSchemaValidator

def main():
    print("=== NEW MODEL CONFIGURATION TEST ===")
    
    validator = CerebrasSchemaValidator()
    
    # Test all models to see their mode assignment
    print(f"Available models: {len(validator.available_models)}")
    print(f"Schema mode override models: {validator.schema_mode_models}")
    
    print("\n=== MODEL MODE ASSIGNMENTS ===")
    for model in validator.available_models:
        uses_schema = model.name in validator.schema_mode_models
        mode = "üîß Schema mode" if uses_schema else "üìù JSON mode"
        status = "(FIXED)" if uses_schema and "thinking" in model.name else ""
        print(f"{mode} {model.display_name} ({model.name}) {status}")
    
    print("\n=== PROBLEM RESOLUTION ===")
    print("‚úÖ Qwen 3 235B Thinking added to schema mode override")
    print("‚úÖ Will use strict schema enforcement instead of JSON mode")
    print("‚úÖ Should prevent 400 Bad Request errors from verbosity")
    print("‚úÖ Other models remain in JSON mode for optimal performance")
    
    print("\n=== EXPECTED BEHAVIOR IMPROVEMENT ===")
    print("üîß Qwen 3 235B Thinking: Schema mode ‚Üí More structured, less verbose")
    print("üìù GPT OSS 120B: JSON mode ‚Üí Fast and flexible (monitor for issues)")
    print("üìù Other models: Continue working as before")
    
    print("\nüéâ System optimized for new model characteristics!")

if __name__ == "__main__":
    main()